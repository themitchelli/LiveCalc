# FADE Project Export
# Generated: 2026-01-26 23:09:41

## Versions

- FADE CLI: v0.3.1
- prompt.md: v0.3.1

## Folder Structure

```
./ANALYSIS-SUMMARY.txt
./complexity-estimation-analysis.md
./ESTIMATION-ANALYSIS-INDEX.md
./estimation-improvement-strategy.md
./fade-export.txt
./fade/discoveries/README.md
./fade/discoveries/SPIKE-LC-007-US-S01-multithreading-regression.md
./fade/learned.md
./fade/prd-archive/PRD-LC-001-cpp-projection-engine.json
./fade/prd-archive/PRD-LC-002-wasm-compilation-threading.json
./fade/prd-archive/PRD-LC-003-vscode-extension-foundation.json
./fade/prd-archive/PRD-LC-004-results-panel-visualisation.json
./fade/prd-archive/PRD-LC-005-auto-run-hot-reload.json
./fade/prd-archive/PRD-LC-006-assumptions-manager-integration.json
./fade/prd-archive/PRD-LC-010-modular-orchestration-layer.json
./fade/prd-archive/PRD-LC-012-cloud-runtime-execution-bridge.json
./fade/prd-archive/PRD-LC-013-cloud-platform-management.json
./fade/prd-archive/PRD-LC-014-standards-documentation.json
./fade/prd-archive/SPIKE-LC-007-engine-performance-infrastructure.json
./fade/prd-archive/SPIKE-SPIKE-LC-007-calcengine.json
./fade/progress 2.md
./fade/tests/SPIKE-LC-007/run_all_tests.sh
./fade/tests/SPIKE-LC-007/SKIP_us-s01_02_document_root_cause.md
./fade/tests/SPIKE-LC-007/SKIP_us-s02_05_documentation.md
./fade/tests/SPIKE-LC-007/SKIP_us-s03_05_cpu_utilization.md
./fade/tests/SPIKE-LC-007/test_us-s01_01_profile_worker_overhead.sh
./fade/tests/SPIKE-LC-007/test_us-s01_03_8workers_4x_faster.sh
./fade/tests/SPIKE-LC-007/test_us-s01_04_benchmark_validates.sh
./fade/tests/SPIKE-LC-007/test_us-s02_01_calcengine_interface.sh
./fade/tests/SPIKE-LC-007/test_us-s02_02_livecalc_adapter.sh
./fade/tests/SPIKE-LC-007/test_us-s02_03_worker_uses_interface.sh
./fade/tests/SPIKE-LC-007/test_us-s02_04_mock_engine.sh
./fade/tests/SPIKE-LC-007/test_us-s03_01_workstealingpool_class.sh
./fade/tests/SPIKE-LC-007/test_us-s03_02_lifo_local.sh
./fade/tests/SPIKE-LC-007/test_us-s03_04_lockfree_sab.sh
./fade/tests/SPIKE-LC-007/test_us-s03_06_longtail_elimination.sh
./fade/tests/SPIKE-LC-007/test_us-s03_07_fallback_static.sh
./fade/tests/SPIKE-LC-007/test_us-s04_01_cmake_simd_flag.sh
./fade/tests/SPIKE-LC-007/test_us-s04_02_simd_wasm_built.sh
./fade/tests/SPIKE-LC-007/test_us-s04_03_simd_tests_exist.sh
./fade/tests/SPIKE-LC-007/test_us-s04_05_simd_benchmark.sh
./fade/tests/SPIKE-LC-007/test_us-s04_06_browser_support.sh
./fade/tests/SPIKE-LC-007/test_us-s05_01_baseline_captured.sh
./fade/tests/SPIKE-LC-007/test_us-s05_02_spike_benchmark.sh
./fade/tests/SPIKE-LC-007/test_us-s05_03_comparison_report.sh
./fade/tests/SPIKE-LC-007/test_us-s05_04_report_metrics.sh
./fade/tests/SPIKE-LC-007/test_us-s05_05_recommendation.sh
./fade/tests/SPIKE-LC-007/test_us-s05_06_fade_compatible.sh
./MOCK-HEALING-REPORT-PRD-LC-013.md
./prd-estimation-data.csv
```

## FADE.md

```markdown
<!-- FADE FADE.md v0.3.1 -->

# LiveCalc

<!-- FADE.md - Project context for AI coding agents. This file is READ-ONLY for agents. -->

---

## Project Overview

LiveCalc provides **instant actuarial model feedback** through a VS Code extension powered by a high-performance WASM calculation engine.

**What problem does it solve?**
- Eliminates the traditional actuarial workflow delay: write model → export to Excel/Python → wait for results → iterate
- Provides sub-second feedback for model changes with auto-run on save
- Scales from desktop (1K scenarios) to cloud (1M+ scenarios) seamlessly
- Enables collaborative modeling with centralized assumption management

**Who are the users?**
- Actuaries building and testing life insurance projection models
- Actuarial teams collaborating on shared assumption libraries
- Platform engineers deploying cloud-scale actuarial computations

**Current state:**
- **MVP Complete**: Core engine (C++/WASM), VS Code extension with results visualization, assumptions manager integration, modular pipeline orchestration
- **In Progress**: Cloud execution infrastructure (Azure Batch), remote debugging capabilities
- **Planned**: Model versioning, collaborative features, production deployment

**Tech Stack:**
- **Core Engine**: C++ compiled to WASM via Emscripten (with SIMD support)
- **Desktop**: TypeScript (VS Code extension), Web Workers for parallelism
- **Cloud API**: Python (FastAPI), Azure services (Blob Storage, Batch, Key Vault)
- **Infrastructure**: Terraform (Azure), Kubernetes (AKS), GitHub Actions (CI/CD)

**Repository:** https://github.com/themitchelli/LiveCalc

---

## Coding Standards

<!--
Define how code should be written in this project. Link to external style guides
rather than duplicating them. Include project-specific conventions that differ
from or extend the standard guides.
-->

### Style Guides

- **TypeScript:** [Google TypeScript Style Guide](https://google.github.io/styleguide/tsguide.html)
- **Python:** [PEP 8](https://peps.python.org/pep-0008/)
- **API Design:** [JSON:API Specification](https://jsonapi.org/)

### Project Conventions

- Naming: `camelCase` for variables, `PascalCase` for components
- Tests: Co-locate with source files as `*.test.ts`
- Commits: Conventional commits format (`feat:`, `fix:`, `chore:`)

---

## Standards

<!--
Link to detailed standards documents. These are loaded by Claude when working
on relevant tasks. Add your own project-specific standards as needed.
-->

| Standard | Description |
|----------|-------------|
| [API Security](standards/api-security.md) | API-first strategy, security by design, JWT auth, tenant isolation |
| [Git](standards/git.md) | Commit messages, branch naming, FADE-specific conventions |
| [Coding](standards/coding.md) | Naming, comments philosophy, error handling, code organization |
| [Testing](standards/testing.md) | Test pyramid, performance benchmarks, regression protection |
| [Infrastructure](standards/infrastructure.md) | Everything as code (Terraform, Helm, config) |
| [Documentation](standards/documentation.md) | README structure, API docs, code comments, what NOT to document |

---

## Architecture References

### System Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                       VS Code Extension                          │
│  ┌─────────────────┐  ┌──────────────┐  ┌──────────────────┐  │
│  │ Results Panel   │  │ Pipeline     │  │ Assumptions      │  │
│  │ (Webview)       │  │ Debugger     │  │ Manager Client   │  │
│  └─────────────────┘  └──────────────┘  └──────────────────┘  │
│           │                    │                    │            │
│           └────────────────────┴────────────────────┘            │
│                              ↓                                   │
│                  ┌───────────────────────┐                       │
│                  │  LiveCalc Engine Mgr  │                       │
│                  │  (TypeScript)         │                       │
│                  └───────────────────────┘                       │
│                              ↓                                   │
│         ┌────────────────────┴────────────────────┐             │
│         ↓                                          ↓             │
│  ┌─────────────┐                          ┌──────────────┐     │
│  │   Main      │    SharedArrayBuffer     │ Worker Pool  │     │
│  │   Thread    │◄────────(bus://)────────►│ (N workers)  │     │
│  │             │                          │              │     │
│  │  ┌────────┐ │                          │ ┌──────────┐ │     │
│  │  │ WASM   │ │                          │ │ WASM     │ │     │
│  │  │ Module │ │                          │ │ Module   │ │     │
│  │  └────────┘ │                          │ └──────────┘ │     │
│  └─────────────┘                          └──────────────┘     │
└─────────────────────────────────────────────────────────────────┘
                              ↑
                              │ JWT Auth + REST API
                              ↓
                 ┌────────────────────────┐
                 │ Assumptions Manager    │
                 │ (Cloud Service)        │
                 │ - Table/Version Mgmt   │
                 │ - Approval Workflow    │
                 │ - Caching              │
                 └────────────────────────┘
                              ↑
                              │ Job Submit API
                              ↓
                 ┌────────────────────────┐
                 │ Cloud Execution        │
                 │ (Azure Batch)          │
                 │ - Large-scale runs     │
                 │ - Blob storage I/O     │
                 │ - Distributed workers  │
                 └────────────────────────┘
```

**Key Architectural Patterns:**
- **Zero-copy parallelism**: SharedArrayBuffer with bus:// protocol eliminates data copying between workers
- **CalcEngine interface**: Pluggable calculation engines (WASM, Python, future: Milliman Integrate)
- **API-first**: All cloud services expose REST APIs consumed by VS Code extension
- **Modular pipelines**: DAG-based orchestration for multi-engine calculations

### Key Documents

| Document | Location | Description |
|----------|----------|-------------|
| Data Flow & Scaling | `docs/architecture/data-flow-and-scaling.md` | Memory budgets, tiered execution (local vs cloud) |
| SIMD Alignment | `livecalc-engine/docs/simd-alignment.md` | 16-byte alignment requirements for SIMD |
| CalcEngine Interface | `livecalc-engine/README.md` | Interface for pluggable engines |
| Pipeline Orchestration | PRD-LC-010 | Modular DAG execution with bus:// resources |

---

## Target Architecture

**Bias toward these patterns in all work, even when the current PRD doesn't directly address them:**

- **API-first design**: Design OpenAPI spec before implementation. All cloud services expose REST APIs.
- **bus:// protocol**: All pipeline data flows through SharedArrayBuffer bus resources (no copying).
- **CalcEngine interface**: All calculation engines implement the standardized interface (initialize, runChunk, dispose).
- **Zero-copy parallelism**: Use SharedArrayBuffer and Atomics for inter-worker communication (no postMessage data copying).
- **16-byte alignment**: All SharedArrayBuffer allocations must be 16-byte aligned for SIMD compatibility.
- **Everything as code**: Infrastructure (Terraform), config (JSON/YAML), docs (Markdown), monitoring (Prometheus rules).
- **Security by design**: Authentication, authorization, encryption, and audit logging considered from the start (not retrofitted).
- **Config-driven**: Feature flags, environment-specific values, and behavior in config files (not hardcoded).

---

---

## Off-Limits Modules

**These directories should NOT be modified by agents:**

| Path | Reason | Contact |
|------|--------|---------|
| `livecalc-engine/build/` | Generated files from CMake/Make | n/a |
| `livecalc-engine/build-wasm*/` | Generated WASM build outputs | n/a |
| `*/node_modules/` | Third-party dependencies managed by npm | n/a |
| `livecalc-vscode/dist/` | Build output from esbuild | n/a |
| `livecalc-vscode/media/vendor/` | Vendored Chart.js and plugins | n/a |
| `.github/workflows/*.yml` | CI/CD configuration (requires human approval) | @platform |

**If you need to modify an off-limits module:** Stop and ask the human for guidance.

---

## Session Boundaries

### Allowed Actions

**Agents may freely perform these actions:**
- Create, modify, delete files in `livecalc-engine/src/`, `livecalc-vscode/src/`, `tests/`, `docs/`, `standards/`
- Add/modify unit and integration tests
- Run tests and linters (`npm test`, `npm run compile`, `make test`)
- Install dev dependencies (`npm install --save-dev`)
- Create feature branches (`feature/PRD-LC-XXX-description`)
- Update PRD files (set `passes: true` after completion)
- Append to `progress.md` and `learned.md`
- Create/modify documentation files (README, standards, architecture docs)

### Requires Human Approval

**Ask before proceeding with:**
- Changes to CI/CD configuration (`.github/workflows/`, `Dockerfile`)
- Cloud infrastructure changes (Terraform, Kubernetes manifests)
- Changes to authentication or authorization logic
- Dependency upgrades (major versions)
- Deleting more than 5 files in one session
- Adding new npm/pip dependencies (production dependencies)
- Creating new Azure services or resources

### Never Do

**Agents must NEVER:**
- Push directly to `main` branch (always use feature branches)
- Commit secrets, API keys, or credentials (use Azure Key Vault references)
- Modify files in `build/`, `dist/`, `node_modules/` directories
- Disable security features (CORS, authentication, TLS validation)
- Run destructive commands on cloud resources
- Disable or skip tests to "make things pass"

---

## System Context

### Current Challenges

- **Performance targets**: Multi-threaded execution must meet <3s for 10K×1K (currently: 370ms ✓)
- **Memory constraints**: Browser-based execution limited by SharedArrayBuffer and WASM memory
- **Cloud integration**: Azure Batch infrastructure in progress (PRD-LC-008)
- **Security hardening**: Assumptions Manager authentication complete, but SAS token scoping needs implementation

### Transition Plan

| Phase | Description | Status |
|-------|-------------|--------|
| Phase 1 | Core Engine & VS Code MVP | ✅ COMPLETE |
| Phase 2 | Assumptions Manager & Pipeline Orchestration | ✅ COMPLETE |
| Phase 3 | Cloud Execution (Azure Batch) | ← CURRENT |
| Phase 4 | Production Deployment & Monitoring | NOT STARTED |

### Active Work Items

- [FEATURE] Cloud execution infrastructure (PRD-LC-008) - in progress
- [FEATURE] Remote debugging capabilities (PRD-LC-012) - planned
- [DOCS] Standards documentation (PRD-LC-014) - in progress
- [SPIKE] Multi-threading performance optimization (SPIKE-LC-007) - ✅ complete

---

## Development Environment

### Local Development

**LiveCalc Engine (C++/WASM):**
```bash
cd livecalc-engine

# Native build for testing
mkdir build && cd build
cmake ..
make
./livecalc_tests

# WASM build (requires Emscripten)
mkdir build-wasm && cd build-wasm
emcmake cmake .. -DCMAKE_BUILD_TYPE=Release
emmake make
```

**VS Code Extension (TypeScript):**
```bash
cd livecalc-vscode
npm install
npm run compile     # TypeScript compilation
npm test           # Run tests
npm run package    # Create .vsix package

# Debug: Press F5 in VS Code to launch Extension Development Host
```

**JavaScript Wrapper (for engine):**
```bash
cd livecalc-engine/js
npm install
npm test                    # Unit and integration tests
npm run benchmark          # Performance benchmarks
```

**Required Tools:**
- Node.js 18+ (for TypeScript and npm)
- Emscripten SDK (for WASM builds)
- CMake 3.20+ (for C++ builds)
- VS Code 1.85.0+ (for extension development)

**Environment Variables:**
- None required for local development
- Cloud API credentials stored in VS Code SecretStorage (encrypted)

### Production/Deployment

**VS Code Extension:**
- Packaged as `.vsix` file via `npm run package`
- Published to VS Code Marketplace (manual process, requires publisher account)
- Version managed in `package.json`

**Cloud API (future):**
- Deployed to Azure Kubernetes Service (AKS) via Helm charts
- Infrastructure managed via Terraform
- CI/CD via GitHub Actions (`.github/workflows/`)
- Secrets stored in Azure Key Vault

---

## Additional Context

### Known Gotchas

- **SIMD builds require 16-byte alignment**: All SharedArrayBuffer allocations must use `alignUp(size, 16)` not just 8-byte alignment
- **BigInt for uint64_t**: WASM functions with `uint64_t` parameters require `BigInt(value)` in JavaScript
- **SharedArrayBuffer requires headers**: Browsers need `Cross-Origin-Opener-Policy: same-origin` and `Cross-Origin-Embedder-Policy: require-corp`
- **Worker pool overhead**: Cold start includes ~200ms (init + load). Use warm timing for production benchmarks.
- **CRC32 performance**: Integrity checking adds ~1ms per MB. Disabled by default, enable for debugging.

### Recent Major Changes

- **2026-01-24**: Completed modular pipeline orchestration (PRD-LC-010) with bus:// protocol and breakpoint debugging
- **2026-01-24**: Integrated Assumptions Manager (PRD-LC-006) with JWT auth and local caching
- **2026-01-24**: Implemented auto-run on save (PRD-LC-005) with smart re-run optimization
- **2026-01-24**: Added comprehensive results visualization (PRD-LC-004) with comparison and export
- **2026-01-23**: Multi-threading via work-stealing scheduler (SPIKE-LC-007) achieving 5.6x speedup

### Upcoming Changes

- **PRD-LC-008**: Cloud execution infrastructure with Azure Batch for large-scale runs (100K+ policies)
- **PRD-LC-012**: Remote debugging API for step-through debugging of cloud-executed models
- **Production deployment**: Monitoring, alerting, and operational readiness for cloud services

---

## Fragile Areas

<!--
Known problem spots. Exercise extra caution here - smaller commits, more
verification, ask before major refactoring. Remove when cleaned up.
-->

| Area | Why it's fragile |
|------|------------------|
| `example/path/` | Example: Changes cascade unpredictably |
| `another/module.py` | Example: Looks simple, always takes 5x longer |
```

## Standards

### api-security.md

```markdown
# API Security Standard

Guidelines for building secure APIs. Apply these when generating or reviewing API code.

---

## 1. Authenticate by Default

Every endpoint requires authentication unless explicitly marked public.

**Apply:**
- Add auth middleware to all routes by default
- Use bearer tokens or API keys with proper validation
- Never trust client-provided user IDs—extract from verified token

**Rationale:** Unauthenticated endpoints are the #1 source of API vulnerabilities. Default-secure means you must opt OUT of auth, not opt IN.

---

## 2. Object-Level Authorization

Verify the authenticated user can access the specific resource being requested.

**Apply:**
- Check ownership or role permissions before returning data
- Use `WHERE user_id = ?` in queries, not just `WHERE id = ?`
- Never trust that a valid session means access to all resources

```python
# Bad - only checks if object exists
def get_order(order_id):
    return Order.query.get(order_id)

# Good - checks ownership
def get_order(order_id, current_user):
    return Order.query.filter_by(id=order_id, user_id=current_user.id).first_or_404()
```

**Rationale:** BOLA (Broken Object Level Authorization) is OWASP API #1. Users can enumerate IDs; you must verify they own what they're requesting.

---

## 3. Schema-First Input Validation

Define expected input shape; reject anything that doesn't match.

**Apply:**
- Use schema validation (Zod, Pydantic, JSON Schema) on all inputs
- Validate type, format, length, and allowed values
- Reject requests with extra fields (disallow unknown)
- Validate path params, query params, headers—not just body

```typescript
// Good - explicit schema
const createUserSchema = z.object({
  email: z.string().email().max(255),
  name: z.string().min(1).max(100),
  role: z.enum(['user', 'admin']).default('user')
}).strict();  // Rejects extra fields
```

**Rationale:** Unvalidated input leads to injection, type confusion, and mass assignment. Schema validation catches these at the boundary.

---

## 4. Least Data Returned

Return only fields the client needs; never expose internal fields.

**Apply:**
- Define response schemas; don't return raw database objects
- Exclude: IDs of related objects the user can't access, internal timestamps, soft-delete flags, hashed passwords, tokens
- Use explicit allow-lists, not block-lists

```javascript
// Bad - returns entire user object
return user;

// Good - explicit response shape
return {
  id: user.id,
  name: user.name,
  email: user.email
};
```

**Rationale:** Excess data exposure leaks information attackers use for enumeration, privilege escalation, or further attacks.

---

## 5. Rate Limiting

Limit request frequency to prevent abuse and brute-force attacks.

**Apply:**
- Apply rate limits at API gateway or middleware level
- Stricter limits on auth endpoints (login, password reset)
- Include rate limit headers in responses (`X-RateLimit-*`)
- Consider per-user AND per-IP limits

| Endpoint Type | Suggested Limit |
|---------------|-----------------|
| Public read | 100/min |
| Authenticated | 300/min |
| Auth (login, signup) | 10/min |
| Password reset | 5/min |

**Rationale:** Without rate limits, attackers can brute-force credentials, enumerate resources, or DoS your API.

---

## 6. Parameterized Queries

Never interpolate user input into SQL, commands, or queries.

**Apply:**
- Use parameterized queries or ORM methods exclusively
- Never use string concatenation or f-strings for queries
- Same rule for NoSQL, shell commands, LDAP queries

```python
# Bad - SQL injection
cursor.execute(f"SELECT * FROM users WHERE email = '{email}'")

# Good - parameterized
cursor.execute("SELECT * FROM users WHERE email = %s", (email,))
```

**Rationale:** Injection attacks (SQL, NoSQL, command) remain in OWASP top 10. Parameterized queries make injection structurally impossible.

---

## 7. Secure Error Handling

Return safe error messages; log detailed errors server-side.

**Apply:**
- Use generic client messages: "Not found", "Unauthorized", "Invalid request"
- Never expose: stack traces, SQL errors, file paths, internal IPs
- Log full details server-side for debugging
- Use consistent error response format

```json
// Good - safe client response
{
  "error": "Not found",
  "code": "RESOURCE_NOT_FOUND"
}

// Server log (not returned to client)
// "User 123 attempted to access Order 456 (not owner) at 2024-01-15T10:30:00Z"
```

**Rationale:** Detailed errors help attackers understand your stack, find vulnerabilities, and craft exploits.

---

## Quick Reference

| Principle | Key Action |
|-----------|------------|
| Auth by default | Add middleware to ALL routes |
| Object-level authz | Check ownership, not just existence |
| Schema validation | Validate ALL input with explicit schemas |
| Least data | Return allow-listed fields only |
| Rate limiting | Apply limits, stricter on auth |
| Parameterized queries | Never interpolate user input |
| Safe errors | Generic to client, detailed in logs |

---

## When to Read This Standard

Read this document when:
- Creating new API endpoints
- Reviewing API code for security
- Designing authentication or authorization flows
- Handling user input or database queries
```

### architecture.md

```markdown
# Architecture Standard

Questions to guide architectural decisions. Reference this when designing systems, adding services, or making infrastructure choices.

*Adapted from [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/). Principles are generic; apply to any project type.*

---

## 1. Operational Excellence

Can you deploy, monitor, and evolve this system confidently?

**Consider:**
- How will you deploy changes? (CI/CD, rollback strategy)
- What happens when something fails at 2 AM? (alerts, runbooks)
- How do you know the system is healthy? (metrics, logs, dashboards)
- Can the team maintain this in 6 months? (documentation, simplicity)

**Apply:**
- Automate deployments—no manual steps in production
- Add health checks and structured logging from the start
- Design for incremental changes, not big-bang releases
- Document operational procedures alongside code

---

## 2. Security

Is access controlled and data protected at every layer?

**Consider:**
- Who can access this system? How is identity verified?
- What's the blast radius if credentials leak?
- Is sensitive data encrypted in transit and at rest?
- How do you detect and respond to security incidents?

**Apply:**
- Apply least-privilege: grant minimum necessary permissions
- Never store secrets in code; use environment variables or vaults
- Encrypt all external communication (HTTPS, TLS)
- Log access attempts; alert on anomalies

*See also: `standards/api-security.md` for API-specific security.*

---

## 3. Reliability

Will this system recover gracefully when things go wrong?

**Consider:**
- What happens when a dependency fails? (timeout, retry, fallback)
- How does the system behave under unexpected load?
- What's the recovery process for data loss?
- Are there single points of failure?

**Apply:**
- Design for failure: timeouts, circuit breakers, graceful degradation
- Test failure scenarios (dependency down, disk full, OOM)
- Implement backups and verify restore procedures
- Avoid single points of failure in critical paths

---

## 4. Performance

Is the system fast enough for users and efficient in resource use?

**Consider:**
- What are the latency requirements? (P50, P95, P99)
- Where are the likely bottlenecks? (DB queries, network, compute)
- How does performance scale with load?
- Are you caching effectively without creating consistency issues?

**Apply:**
- Measure before optimizing—profile, don't guess
- Cache at appropriate layers (CDN, app, DB)
- Use async/background processing for slow operations
- Set performance budgets and monitor against them

---

## 5. Cost

Are you spending efficiently, avoiding waste?

**Consider:**
- What does this cost to run? (compute, storage, bandwidth)
- Are resources right-sized, or over-provisioned "just in case"?
- Do you have visibility into cost drivers?
- What's the cost of not doing this? (opportunity cost)

**Apply:**
- Start small; scale based on measured need
- Use autoscaling rather than over-provisioning
- Review costs regularly; sunset unused resources
- Consider cost in technology choices (managed vs self-hosted)

---

## 6. Sustainability

Is this system efficient and maintainable long-term?

**Consider:**
- Are resources utilized efficiently? (CPU, memory, storage)
- Does the architecture minimize unnecessary computation?
- Can this system evolve without major rewrites?
- Is the technical debt manageable?

**Apply:**
- Right-size resources; shut down idle environments
- Avoid premature optimization but design for efficiency
- Keep dependencies minimal and up-to-date
- Refactor incrementally; don't let debt compound

---

## Quick Reference

| Pillar | Core Question |
|--------|---------------|
| Operational Excellence | Can we deploy and operate confidently? |
| Security | Is access controlled, data protected? |
| Reliability | Does it recover gracefully from failure? |
| Performance | Is it fast enough, efficient enough? |
| Cost | Are we spending wisely? |
| Sustainability | Is it efficient and maintainable long-term? |

---

## When to Read This Standard

Read this document when:
- Designing a new system or service
- Adding significant infrastructure (databases, queues, caches)
- Making technology choices (build vs buy, language, framework)
- Reviewing architecture decisions
- Planning for scale or reliability improvements
```

### coding.md

```markdown
# Coding Standard

Guidelines for writing clean, maintainable code. Apply these across all languages.

---

## Naming Conventions

Names should reveal intent. A reader should understand what something does from its name alone.

### Variables and Functions

| Type | Convention | Example |
|------|------------|---------|
| Variables | camelCase (JS/TS), snake_case (Python) | `userCount`, `user_count` |
| Functions | camelCase (JS/TS), snake_case (Python) | `calculateTotal()`, `calculate_total()` |
| Constants | UPPER_SNAKE_CASE | `MAX_RETRY_COUNT`, `API_TIMEOUT` |
| Classes | PascalCase | `UserService`, `OrderProcessor` |
| Booleans | Prefix with is/has/can/should | `isActive`, `hasPermission` |

### Naming Rules

**Do:**
- Use full words, not abbreviations (`customer` not `cust`)
- Name functions as verbs: `getUser()`, `validateInput()`, `sendEmail()`
- Name booleans as questions: `isValid`, `hasAccess`, `canEdit`
- Be consistent with project conventions

**Don't:**
- Use single letters except loop counters (`i`, `j`)
- Use Hungarian notation (`strName`, `intCount`)
- Use generic names (`data`, `info`, `temp`, `stuff`)

```javascript
// Bad
const d = getD();
const temp = process(d);

// Good
const orderDetails = getOrderDetails();
const formattedOrder = formatForDisplay(orderDetails);
```

---

## Function Guidelines

### Keep Functions Small

- **Target:** 20-30 lines maximum
- **One job:** Each function does one thing
- **One level of abstraction:** Don't mix high-level and low-level operations

```python
# Bad - does too much
def process_order(order):
    validate(order)
    tax = order.subtotal * 0.1
    total = order.subtotal + tax
    send_email(order.user.email, f"Total: {total}")
    db.save(order)
    log(f"Order processed: {order.id}")

# Good - separated concerns
def process_order(order):
    validate_order(order)
    order.total = calculate_total(order)
    save_order(order)
    notify_customer(order)
```

### Function Parameters

- **Maximum:** 3 parameters preferred, 4 acceptable
- **Too many?** Use an options object or refactor
- **Order:** Required first, optional last

```typescript
// Bad - too many params
function createUser(name, email, age, role, department, manager) {}

// Good - options object
function createUser(name: string, email: string, options?: UserOptions) {}
```

---

## File Organization

### File Length

- **Target:** 200-300 lines maximum
- **Too long?** Split into focused modules
- **Exception:** Test files can be longer

### File Structure

1. Imports (external, then internal)
2. Constants/types
3. Main exports
4. Helper functions (private)

```typescript
// 1. External imports
import { z } from 'zod';

// 2. Internal imports
import { db } from '../db';

// 3. Constants/types
const MAX_RETRIES = 3;
type UserRole = 'admin' | 'user';

// 4. Main exports
export function getUser(id: string) { ... }

// 5. Helpers (not exported)
function validateId(id: string) { ... }
```

---

## Error Handling

### Use Explicit Error Handling

- Check for errors at boundaries (API, DB, external services)
- Let errors propagate where appropriate
- Don't swallow errors silently

```python
# Bad - silent failure
def get_user(id):
    try:
        return db.find(id)
    except:
        return None  # Hides real errors

# Good - explicit handling
def get_user(id):
    try:
        return db.find(id)
    except DatabaseError as e:
        logger.error(f"DB error fetching user {id}: {e}")
        raise ServiceError("Unable to fetch user")
```

### Error Messages

- Include context: what failed, why, what to do
- Never expose internal details to users
- Log details server-side, return safe messages to clients

---

## Comments

### When to Comment

**Do comment:**
- Why, not what (the code shows what)
- Complex algorithms or business rules
- Workarounds with links to issues
- Public API documentation

**Don't comment:**
- Obvious code (`i++; // increment i`)
- Commented-out code (delete it)
- TODOs without context or owners

```javascript
// Bad - states the obvious
// Get the user by ID
const user = getUser(id);

// Good - explains why
// Use legacy endpoint until v2 migration complete (PROJ-123)
const user = legacyGetUser(id);
```

### Self-Documenting Code

Prefer clear code over comments:

```python
# Bad - needs comment to explain
# Check if user can access resource
if user.role == 'admin' or (user.role == 'member' and resource.owner == user.id):

# Good - self-documenting
if user.can_access(resource):
```

---

## Language-Specific Rules

### JavaScript/TypeScript
- Use `const` by default, `let` when reassignment needed
- Prefer arrow functions for callbacks
- Use optional chaining (`?.`) and nullish coalescing (`??`)

### Python
- Follow PEP 8
- Use type hints for function signatures
- Prefer list/dict comprehensions for simple transformations

### General
- Follow the language's official style guide
- Use the project's linter configuration
- Match existing code style in the file

---

## Quick Reference

| Principle | Guideline |
|-----------|-----------|
| Naming | Reveal intent, be consistent |
| Functions | Small (20-30 lines), one job each |
| Files | 200-300 lines max, focused modules |
| Parameters | 3 preferred, use options object if more |
| Errors | Explicit handling, meaningful messages |
| Comments | Explain why, not what |

---

## When to Read This Standard

Read this document when:
- Writing new code
- Reviewing code for style and maintainability
- Refactoring existing code
- Onboarding to a new codebase
```

### documentation.md

```markdown
# Documentation Standard

Guidelines for what to document and how. Apply these to avoid under or over-documenting.

---

## Documentation Philosophy

Document the **why**, not the **what**. Code shows what happens; documentation explains why it exists and how to use it.

**Golden rule:** If someone needs information that isn't in the code itself, document it. If the code already tells the story, don't repeat it in prose.

---

## Documentation Layers

Different audiences need different docs:

| Layer | Audience | Location | Updates |
|-------|----------|----------|---------|
| README | New contributors | Repo root | When setup changes |
| API docs | Consumers | `/docs/api/` or inline | When API changes |
| ADRs | Future maintainers | `/docs/adr/` | When decisions made |
| Code comments | Developers | In source | With code changes |
| FADE files | AI agents | `/fade/` | Per session |

---

## README Structure

Every README should answer these questions, in this order:

1. **What** - One paragraph explaining what this project does
2. **Quick start** - Get running in under 5 minutes
3. **Prerequisites** - Required tools and versions
4. **Installation** - Step-by-step setup
5. **Usage** - Common commands or API examples
6. **Configuration** - Environment variables, options

**Keep it short.** Link to detailed docs rather than embedding everything.

```markdown
# Project Name

Brief description (1-2 sentences).

## Quick Start

\`\`\`bash
npm install
npm start
\`\`\`

## Prerequisites

- Node.js 18+
- PostgreSQL 14+

## Configuration

See [Configuration Guide](docs/config.md) for all options.
```

---

## API Documentation

Document public APIs with:

- **Endpoint** - HTTP method and path
- **Parameters** - Required and optional, with types
- **Response** - Success and error shapes
- **Example** - Working request/response

```markdown
## POST /users

Create a new user.

**Request:**
| Field | Type | Required | Description |
|-------|------|----------|-------------|
| email | string | Yes | User email |
| name | string | No | Display name |

**Response (201):**
\`\`\`json
{ "id": "usr_123", "email": "user@example.com" }
\`\`\`

**Errors:** 400 (validation), 409 (duplicate email)
```

---

## Architecture Decision Records (ADRs)

Use ADRs to capture **why** major decisions were made.

### ADR Template

```markdown
# ADR-001: Use PostgreSQL for primary database

## Status
Accepted (2024-01-15)

## Context
We need a database for user data and transactions.

## Decision
Use PostgreSQL.

## Rationale
- ACID compliance for financial data
- Team expertise
- JSON support for flexible schemas

## Consequences
- Need to manage connection pooling
- Migrations required for schema changes
```

### When to Write an ADR

- Choosing a technology or framework
- Architectural patterns (monolith vs microservices)
- Security model decisions
- Breaking changes to public APIs

---

## Code Comments

See [Coding Standard](coding.md) for detailed comment guidelines.

**Quick rules:**
- Comment **why**, not what
- Link to tickets for workarounds
- Delete commented-out code
- Public APIs need docstrings

---

## FADE-Specific Documentation

### progress.md
- Append after each story completes
- Include: summary, files changed, test status
- Use format from prompt.md

### learned.md
- Only add reusable discoveries
- Must be non-obvious and actionable
- Skip story-specific implementation details

### FADE.md (human-maintained)
- Keep current with project changes
- Update off-limits modules as code evolves
- Review quarterly

---

## What NOT to Document

Avoid creating documentation that:

| Anti-pattern | Why It's Bad | Instead |
|--------------|--------------|---------|
| Restating code | Drifts out of sync | Write clearer code |
| Implementation details | Changes frequently | Document interfaces |
| Obvious setup | Wastes reader time | Assume basic skills |
| Giant walls of text | Nobody reads them | Use bullet points |
| Every function | Maintenance burden | Document public APIs |

**Specifically, do NOT:**
- Add docstrings to private/internal functions
- Document self-explanatory code
- Create README sections for obvious things
- Write tutorials for standard tools
- Duplicate information across files

---

## Quick Reference

| Doc Type | When to Write | Keep Updated |
|----------|---------------|--------------|
| README | Project creation | On setup changes |
| API docs | New/changed endpoints | With API changes |
| ADRs | Major decisions | Never (immutable) |
| Code comments | Complex/non-obvious code | With code changes |
| progress.md | After each story | Each session |
| learned.md | New discoveries | When learned |

---

## When to Read This Standard

Read this document when:
- Creating a new project or module
- Writing or updating documentation
- Reviewing PRs with doc changes
- Deciding whether something needs documenting
- Cleaning up existing documentation
```

### git.md

```markdown
# Git Standard

Guidelines for commits, branches, and version control. Apply these when working with git.

---

## Commit Message Format

Use conventional commits: `<type>: <description>`

```
feat: add user authentication endpoint
fix: handle null values in order calculation
docs: update API reference for new endpoints
```

### Type Prefixes

| Type | When to Use |
|------|-------------|
| `feat:` | New feature or capability |
| `fix:` | Bug fix |
| `docs:` | Documentation only |
| `chore:` | Maintenance, dependencies, config |
| `refactor:` | Code restructure, no behavior change |
| `test:` | Adding or updating tests |
| `spike:` | Exploratory work (spike branches only) |

### Writing Good Messages

**Do:**
- Start with lowercase after the colon
- Use imperative mood ("add feature" not "added feature")
- Keep first line under 72 characters
- Explain what and why, not how

**Don't:**
- Include ticket numbers in the subject (use body if needed)
- Use vague messages like "fix bug" or "update code"
- Combine unrelated changes in one commit

```bash
# Good
feat: add rate limiting to auth endpoints
fix: prevent duplicate order submissions
refactor: extract validation logic into middleware

# Bad
feat: Added new stuff
fix: bug fix
chore: updates
```

---

## Branch Strategy

### Trunk-Based Development (Default)

Work directly on `main` or short-lived feature branches.

**Apply:**
- Keep branches short-lived (hours to days, not weeks)
- Merge frequently to avoid drift
- Use feature flags for incomplete features in main
- Delete branches after merging

### Feature Branches

For larger work that can't be completed quickly:

```bash
# Naming convention
feature/add-user-auth
bugfix/order-calculation-null
chore/upgrade-dependencies
```

**Branch naming:**
- Use kebab-case (lowercase, hyphens)
- Prefix with type: `feature/`, `bugfix/`, `chore/`, `spike/`
- Keep names descriptive but concise

---

## FADE-Specific Conventions

### Story Completion Commits

When completing a FADE user story:

```bash
git add -A && git commit -m "feat: complete US-XXX - Story Title"
```

Use the appropriate type based on the work:
- `feat:` for new features
- `fix:` for bug fixes
- `docs:` for documentation PRDs
- `chore:` for maintenance PRDs

### PRD Checkpoint Commits

After each story completion:
1. Stage all changes: `git add -A`
2. Commit with story reference: `feat: complete US-001 - Add login page`
3. Include the story ID and title for traceability

### Spike Branches

Spikes are exploratory work that stays isolated:

```bash
# Create spike branch
git checkout -b spike/investigate-caching-options

# All spike work stays here
spike: add caching prototype
spike: test Redis vs Memcached performance

# Do NOT merge to main
# Create outputArtifact documenting findings
```

**Spike rules:**
- Always create a dedicated branch
- Use `spike:` prefix for all commits
- Never merge spike branches to main
- Document findings in the spike's outputArtifact

---

## Commit Hygiene

### Atomic Commits

Each commit should be a single logical change.

```bash
# Good - separate concerns
git commit -m "feat: add User model"
git commit -m "feat: add user registration endpoint"
git commit -m "test: add user registration tests"

# Bad - multiple unrelated changes
git commit -m "add user stuff and fix order bug and update docs"
```

### What to Commit

**Always commit:**
- Source code changes
- Test files
- Documentation updates
- Configuration changes

**Never commit:**
- `.env` files or secrets
- Build artifacts (`dist/`, `node_modules/`)
- IDE settings (unless shared)
- Temporary files

### Before Pushing

1. Run tests locally
2. Check for unintended files: `git status`
3. Review changes: `git diff --staged`
4. Ensure commit messages are clear

---

## Protected Branches

### Never Do

- Force push to `main` or `master`
- Push directly to protected branches (use PRs)
- Rewrite history on shared branches

### Main Branch Rules

- All changes via pull request
- Tests must pass before merge
- At least one approval required (if configured)
- Squash or rebase merges preferred

---

## Quick Reference

| Task | Command |
|------|---------|
| Stage all | `git add -A` |
| Commit | `git commit -m "type: message"` |
| Create branch | `git checkout -b type/name` |
| Switch branch | `git checkout branch-name` |
| Delete branch | `git branch -d branch-name` |
| View history | `git log --oneline -10` |

---

## When to Read This Standard

Read this document when:
- Making commits to the repository
- Creating or managing branches
- Completing FADE user stories
- Working on spike PRDs
```

### README.md

```markdown
# Standards Folder

Project-specific standards that Claude reads when performing related work.

## Purpose

Standards files contain actionable guidelines that Claude applies during development.
Unlike general documentation, these are written as instructions Claude can follow.

## Usage

Link standards from FADE.md in the '## Standards' section:

```markdown
## Standards

| Standard | Description |
|----------|-------------|
| [API Security](standards/api-security.md) | Security principles for API development |
| [Git](standards/git.md) | Commit messages and branching conventions |
```

prompt.md instructs Claude to read relevant standards before starting work.

## Creating Custom Standards

1. Create a markdown file in this folder (e.g., `my-standard.md`)
2. Write actionable instructions Claude can apply
3. Keep under 1,500 tokens (~1,100 words) to preserve context window
4. Link from FADE.md '## Standards' section
```

### testing.md

```markdown
# Testing Standard

Guidelines for writing effective tests. Apply these when creating or reviewing test code.

---

## Test Philosophy

Tests exist to catch bugs and enable confident refactoring. Write tests that:
- Catch real bugs, not implementation details
- Survive refactoring without changes
- Run fast enough to run often
- Fail with clear, actionable messages

---

## Test Pyramid

Maintain a healthy distribution of test types:

| Level | Proportion | Speed | What it Tests |
|-------|------------|-------|---------------|
| Unit | 70% | Fast (ms) | Single functions, pure logic |
| Integration | 20% | Medium (s) | Component interactions, DB, APIs |
| E2E | 10% | Slow (min) | Full user flows, critical paths |

**Apply:**
- Most tests should be unit tests (fast, focused)
- Integration tests for boundaries (DB, external APIs)
- E2E tests only for critical user journeys
- When a bug escapes to E2E, push the test down

---

## What to Test

### Test These
- Business logic and calculations
- Edge cases and boundary conditions
- Error handling and failure modes
- Public API contracts
- Complex conditionals

### Skip These
- Framework code (trust your tools)
- Simple getters/setters
- Type system guarantees
- Third-party library internals
- Implementation details (private methods)

```javascript
// Good - tests business rule
test('applies 10% discount for orders over $100', () => {
  const order = createOrder({ subtotal: 150 });
  expect(calculateDiscount(order)).toBe(15);
});

// Bad - tests implementation detail
test('calls discountService.calculate', () => {
  calculateDiscount(order);
  expect(discountService.calculate).toHaveBeenCalled();
});
```

---

## AAA Pattern

Structure every test with Arrange-Act-Assert:

```python
def test_user_can_update_own_profile():
    # Arrange - set up test data
    user = create_user(name="Alice")

    # Act - perform the action
    result = update_profile(user.id, {"name": "Alicia"})

    # Assert - verify the outcome
    assert result.name == "Alicia"
    assert User.find(user.id).name == "Alicia"
```

**Rules:**
- One Act per test (one action being tested)
- Keep Arrange minimal (use factories/fixtures)
- Assert behaviour, not implementation

---

## Test Naming

Names should describe the scenario and expected outcome:

```
// Pattern: [unit]_[scenario]_[expectedResult]
// or: "should [expected behaviour] when [condition]"

// Good
test('calculateTotal returns zero for empty cart')
test('should reject expired tokens')
test('user_login_fails_with_wrong_password')

// Bad
test('calculateTotal')
test('test1')
test('it works')
```

**Apply:**
- Read the name aloud—does it explain what's being tested?
- Include the condition that triggers the behaviour
- Be specific about the expected outcome

---

## Mocking Guidelines

Mock at boundaries, not internals.

### Mock These
- External HTTP calls
- Database (for unit tests)
- Time/dates
- Random number generators
- File system (when necessary)

### Don't Mock These
- The code under test
- Simple utility functions
- Data transformations

```typescript
// Good - mocks external boundary
const fetchUser = jest.spyOn(api, 'fetchUser').mockResolvedValue(mockUser);
const result = await userService.getProfile(userId);
expect(result.name).toBe(mockUser.name);

// Bad - mocks internal implementation
const validate = jest.spyOn(userService, 'validateId');
userService.getProfile(userId);
expect(validate).toHaveBeenCalled();  // Brittle
```

**Principle:** If you're mocking something you own, consider restructuring instead.

---

## Test Independence

Each test must run in isolation.

**Apply:**
- Tests can run in any order
- No shared mutable state between tests
- Each test sets up its own data
- Clean up after tests that use shared resources

```python
# Bad - depends on previous test
def test_create_user():
    global user_id
    user_id = create_user().id

def test_get_user():
    user = get_user(user_id)  # Depends on test_create_user

# Good - independent
def test_get_user():
    user = create_user()  # Creates own data
    result = get_user(user.id)
    assert result.id == user.id
```

---

## Coverage Requirements

Coverage is a tool, not a goal.

| Type | Minimum | Target |
|------|---------|--------|
| Unit | 70% | 80% |
| Integration | Key paths | Critical flows |
| E2E | Happy paths | Core journeys |

**Apply:**
- Cover all branches of business logic
- Don't chase 100%—diminishing returns
- Missing coverage should be intentional

**Red flags:**
- 100% coverage but bugs still ship (testing wrong things)
- Coverage exemptions everywhere
- Tests that only run code without asserting

---

## Quick Reference

| Principle | Guideline |
|-----------|-----------|
| Pyramid | 70% unit, 20% integration, 10% E2E |
| Structure | AAA: Arrange, Act, Assert |
| Naming | Describe scenario and expected outcome |
| Mocking | Mock boundaries, not internals |
| Independence | Each test runs in isolation |
| Coverage | 70-80% unit, focus on business logic |

---

## When to Read This Standard

Read this document when:
- Writing new tests
- Reviewing test code
- Debugging flaky tests
- Deciding what to test or skip
- Setting up test infrastructure
```

## PRD Queue

### PRD-LC-015-polyglot-python-pyodide.json

```json
{
  "id": "PRD-LC-015",
  "complexity": "medium",
  "title": "Polyglot Logic & Python/Pyodide Local Integration",
  "type": "feature",
  "priority": "medium",
  "status": "proposed",
  "created": "2026-01-24",
  "project": "LiveCalc",
  "phase": 4,
  "description": "Enable Tier 2 research flexibility by integrating the Pyodide (WASM) runtime into the modular pipeline. Allows actuaries to write Python-based calculation engines that interact with C++ engines via the Shared Data Bus with minimal copying overhead.",
  "problem": [
    "C++ is mandatory for 1B+ runs but slow for rapid research iteration and statistical prototyping.",
    "Data scientists and actuaries prefer Python for complex scenario shocks and experience analysis.",
    "Context switching between local Python scripts and the calculation engine introduces manual CSV/JSON serialization overhead."
  ],
  "solution": [
    "Implement a Pyodide-based worker host that satisfies the ICalcEngine interface.",
    "Enable Python scripts to map SharedArrayBuffer data into NumPy arrays with minimal overhead.",
    "Support high-speed handoff (<1ms) between C++ and Python nodes in the pipeline DAG.",
    "Provide a robust package management and error reporting system for Python logic."
  ],
  "dependencies": [
    {
      "id": "PRD-LC-010",
      "title": "Modular Orchestration Layer",
      "status": "complete",
      "notes": "The bus:// protocol and DAG orchestrator are archived and stable."
    }
  ],
  "technicalNotes": {
    "runtime": "Pyodide v0.25+ (WASM-based Python)",
    "interop": "SharedArrayBuffer data is mapped into Pyodide's WASM memory space via NumPy.frombuffer/memoryview. While technically a memory-to-memory transfer, it bypasses string serialization.",
    "memoryAlignment": "All bus:// allocations maintain 16-byte alignment. The Python wrapper ensures NumPy views respect these alignment constraints to prevent SIMD traps.",
    "isolation": "Web Worker based execution to prevent blocking the VS Code UI.",
    "performanceTarget": "Handoff overhead < 1ms; Python transformation of 10K scenarios in < 100ms."
  },
  "userStories": [
    {
      "id": "US-POLY-01",
      "title": "Pyodide CalcEngine Adapter",
      "story": "As a developer, I want a Python-based engine host that looks exactly like a C++ engine to the Orchestrator.",
      "acceptanceCriteria": [
        "Implement PyodideEngine class implementing initialize(), runChunk(), and dispose().",
        "Orchestrator can instantiate a .py node alongside a .wasm node in the same DAG.",
        "Worker host correctly loads the Pyodide environment in a background thread."
      ],
      "tech_stack": [
        "Pyodide",
        "TypeScript",
        "Web Workers"
      ],
      "passes": true
    },
    {
      "id": "US-POLY-02",
      "title": "NumPy Memory Mapping",
      "story": "As an actuary, I want to manipulate the raw Data Bus using standard Python arrays.",
      "acceptanceCriteria": [
        "Python script receives the SharedArrayBuffer and an OffsetMap.",
        "NumPy maps the buffer using memoryview/frombuffer with minimal copy overhead.",
        "Success metric: A 10K scenario interest rate shock applied in Python is visible to the next C++ node in < 1ms."
      ],
      "tech_stack": [
        "NumPy",
        "SharedArrayBuffer",
        "Python"
      ],
      "passes": false
    },
    {
      "id": "US-POLY-03",
      "title": "Polyglot Pipeline Validation",
      "story": "As a modeler, I want the system to ensure my C++ and Python nodes speak the same 'language'.",
      "acceptanceCriteria": [
        "Pipeline validator checks that Python output buffer size matches C++ input buffer size.",
        "Validation logic detects and warns if a Python node attempts to resize the pre-allocated SAB.",
        "Integration test: Chain C++ ESG -> Python Shocker -> C++ Liability engine."
      ],
      "tech_stack": [
        "TypeScript",
        "JSON Schema"
      ],
      "passes": false
    },
    {
      "id": "US-POLY-04",
      "title": "Error Handling & Diagnostic Logging",
      "story": "As a researcher, I want to see Python print() statements and detailed error tracebacks in my IDE.",
      "acceptanceCriteria": [
        "Python syntax errors fail fast with clear pointers in the VS Code Output channel.",
        "Runtime errors provide a full traceback including line numbers and EngineID.",
        "Timeout protection: Configurable worker timeout (default 30s) prevents infinite loops.",
        "Manual Breakpoints: Calling livecalc.breakpoint() in Python triggers the 'Pause' state in the Results Panel."
      ],
      "tech_stack": [
        "VS Code API",
        "Pyodide Streams"
      ],
      "passes": false
    },
    {
      "id": "US-POLY-05",
      "title": "Python Package Management",
      "story": "As an actuary, I want to use standard Python libraries like Pandas and SciPy in my scripts.",
      "acceptanceCriteria": [
        "Environment pre-loads core libraries: NumPy, Pandas, SciPy.",
        "Config support: 'pythonPackages' field in livecalc.config.json allows defining additional requirements.",
        "Dynamic install: Use micropip to install missing packages at engine initialization.",
        "Caching: Package installations are persisted in the VS Code globalStorageUri."
      ],
      "tech_stack": [
        "micropip",
        "VS Code Storage API"
      ],
      "passes": false
    }
  ],
  "filesToCreate": [
    "livecalc-engine/js/src/engines/pyodide-engine.ts",
    "livecalc-engine/js/src/workers/python-worker-host.js",
    "livecalc-engine/js/tests/pyodide-engine.test.ts",
    "livecalc-engine/js/tests/python-worker-host.test.js",
    "examples/polyglot-pipeline/shock_rates.py",
    "examples/polyglot-pipeline/test_shock_rates.py",
    "examples/polyglot-pipeline/livecalc.config.json"
  ],
  "filesToModify": [
    {
      "file": "livecalc-engine/js/src/orchestrator.ts",
      "changes": "Add factory support for Pyodide engines and runtime detection logic."
    },
    {
      "file": "livecalc-vscode/src/ui/results-panel.ts",
      "changes": "Add support for pausing on Python-triggered manual breakpoints."
    }
  ],
  "estimatedSessions": "4 FADE sessions",
  "risks": [
    {
      "risk": "Pyodide cold-start latency",
      "likelihood": "high",
      "impact": "low",
      "mitigation": "Lazy-load Pyodide only when a Python node is detected; cache package installs."
    },
    {
      "risk": "Memory alignment traps",
      "likelihood": "medium",
      "impact": "medium",
      "mitigation": "Strict enforcement of 16-byte alignment in the bridge layer between SAB and NumPy."
    }
  ],
  "definitionOfDone": [
    "Python logic successfully manipulates SharedArrayBuffer data without string serialization.",
    "Handoff time between C++ and Python nodes is measured at < 1ms.",
    "Pure C++ pipelines maintain 1B/36s performance targets (0 regression).",
    "Python performance target: 10K scenarios processed in < 100ms for standard shocks.",
    "Package management (micropip) successfully installs and caches external dependencies."
  ]
}
```

### PRD-LC-018-local-artifact-sinks.json

```json
{
  "id": "PRD-LC-018",
  "complexity": "medium",
  "title": "Local Artifact Sinks & Persistence",
  "type": "feature",
  "priority": "high",
  "status": "proposed",
  "created": "2026-01-25",
  "project": "LiveCalc",
  "phase": 3,
  "description": "Solves the volatility of WASM SharedArrayBuffer memory by providing dedicated 'Sink' nodes in the modular pipeline. Enables automated persistence of bus:// resources to the local workspace in high-performance formats like Parquet and CSV.",
  "problem": [
    "WASM RAM is volatile; closing VS Code or a worker crash results in immediate data loss.",
    "Actuaries currently have to manually export results via the UI, which is not repeatable or auditable.",
    "Downstream analytical tools (PowerBI, Excel, Python scripts) cannot access results unless they are persisted to the physical file system."
  ],
  "solution": [
    "Introduce a new 'sink' node type to the livecalc.config.json DAG schema.",
    "Implement an automated File Persistence Service that writes bus:// memory segments to disk at the end of a run.",
    "Support Apache Parquet via parquet-wasm as the primary high-performance storage format.",
    "Provide a command to load persisted results back into the Results Panel for audit and comparison."
  ],
  "dependencies": [
    {
      "id": "PRD-LC-010",
      "title": "Modular Orchestration Layer",
      "status": "complete",
      "notes": "Requires the bus:// protocol to identify which memory blocks to persist."
    },
    {
      "id": "PRD-LC-015",
      "title": "Polyglot Logic",
      "status": "proposed",
      "optional": true,
      "notes": "Enables Python transformations to be persisted. Sinks will work with C++ engines initially."
    }
  ],
  "technicalNotes": {
    "persistenceEngine": "Extension Host (Node.js) via vscode.workspace.fs API.",
    "parquetLibrary": "parquet-wasm (Rust-based, ~2MB bundle, SNAPPY compression).",
    "trigger": "Execution Lifecycle Hook (onPipelineComplete).",
    "naming": "results_{timestamp}_{jobId}.parquet",
    "sinkConfigExample": {
      "id": "persist-npv",
      "type": "sink",
      "input": "bus://liability_results",
      "format": "parquet",
      "path": "./results/npv_{timestamp}.parquet",
      "schema": {
        "columns": ["policyId", "scenario", "npv"],
        "types": ["int32", "int32", "float64"]
      }
    }
  },
  "userStories": [
    {
      "id": "US-SINK-01",
      "title": "Declarative Sink Nodes with Schema",
      "story": "As a modeler, I want to define the structure of data saved to disk so that downstream tools can parse it correctly.",
      "acceptanceCriteria": [
        "livecalc.config.json supports 'sink' nodes with a mandatory 'schema' field.",
        "Schema validation fails fast if column counts or types do not align with bus:// resource size.",
        "Support for multiple sinks per pipeline (e.g., raw cashflows and summary stats)."
      ],
      "tech_stack": ["JSON Schema", "TypeScript"],
      "passes": false
    },
    {
      "id": "US-SINK-02",
      "title": "Compressed Parquet Persistence",
      "story": "As an actuary, I want my results saved in a compressed format that supports high-speed querying.",
      "acceptanceCriteria": [
        "Sink node converts SAB binary data to Parquet using SNAPPY compression.",
        "Parquet metadata includes embedded Job ID, Model Hash, and Timestamp.",
        "Performance: Persisting 1M policies × 10 scenarios (summary stats) takes < 5s."
      ],
      "tech_stack": ["parquet-wasm", "SharedArrayBuffer"],
      "passes": false
    },
    {
      "id": "US-SINK-03",
      "title": "Success Notification & Explorer Integration",
      "story": "As a user, I want a clear confirmation that my results have been saved to my workspace.",
      "acceptanceCriteria": [
        "Success notification appears on completion showing the file path.",
        "Notification includes 'Open in Explorer' and 'View in Results Panel' buttons.",
        "The system creates the 'results/' directory automatically if missing."
      ],
      "tech_stack": ["VS Code API"],
      "passes": false
    },
    {
      "id": "US-SINK-04",
      "title": "Streaming CSV Export for Large Datasets",
      "story": "As an actuary, I want to export massive datasets to CSV without crashing my IDE.",
      "acceptanceCriteria": [
        "Support type: 'sink' with format: 'csv' using Node.js streaming.",
        "Capacity: Successfully stream-writes up to 10GB of data from SAB to disk.",
        "Progress reporting: VS Code status bar shows 'Persisting: X% complete' during write."
      ],
      "tech_stack": ["Node.js Streams"],
      "passes": false
    },
    {
      "id": "US-SINK-05",
      "title": "Load Persisted Results for Comparison",
      "story": "As a modeler, I want to load a previously persisted .parquet file to compare against new runs.",
      "acceptanceCriteria": [
        "Command 'LiveCalc: Load Results from File' allows picking local .parquet files.",
        "Parquet reader reconstructs the ResultsPanel state from file metadata.",
        "Loaded results are marked with a [FROM FILE] badge in the UI.",
        "Comparison mode allows using the loaded file as the 'Baseline' for delta calculations."
      ],
      "tech_stack": ["parquet-wasm", "ResultsPanel API"],
      "passes": false
    }
  ],
  "filesToCreate": [
    "livecalc-engine/js/src/sinks/file-sink-manager.ts",
    "livecalc-engine/js/src/sinks/parquet-adapter.ts",
    "livecalc-engine/js/tests/persistence.test.ts"
  ],
  "filesToModify": [
    {
      "file": "livecalc-engine/js/src/orchestrator.ts",
      "changes": "Add onPipelineComplete hook and sink node factory."
    },
    {
      "file": "livecalc-vscode/src/commands/index.ts",
      "changes": "Add 'livecalc.loadResultsFromFile' command implementation."
    }
  ],
  "estimatedSessions": "3 FADE sessions",
  "risks": [
    {
      "risk": "Large file writes causing UI lag",
      "likelihood": "medium",
      "impact": "low",
      "mitigation": "Offload disk I/O to a dedicated worker thread or utilize the VS Code filesystem background throughput."
    },
    {
      "risk": "Parquet-WASM bundle size",
      "likelihood": "low",
      "impact": "medium",
      "mitigation": "Lazy-load the parquet-wasm module only when a Parquet sink is initialized."
    }
  ],
  "definitionOfDone": [
    "A pipeline run generates a valid, compressed .parquet file containing embedded metadata.",
    "Persisted results can be loaded back into the IDE and match the original SAB state bit-for-bit.",
    "The 1B/36s compute benchmark is maintained (persistence time is reported separately).",
    "Audit trail: Manifest links the Job ID to the physical file on disk."
  ]
}
```

### PRD-LC-019A-platform-connectors.json

```json
{
  "id": "PRD-LC-019A",
  "complexity": "medium",
  "title": "Analytic Platform Connectors (Snowflake/Databricks)",
  "type": "feature",
  "priority": "medium",
  "status": "proposed",
  "created": "2026-01-25",
  "project": "LiveCalc",
  "phase": 4,
  "description": "Enables minimal-hop streaming from the WASM Shared Data Bus to Snowflake Stages and Databricks Unity Catalog. Reuses the schema definitions from PRD-LC-018 to automate table creation and data loading.",
  "dependencies": [
    {
      "id": "PRD-LC-018",
      "title": "Local Artifact Sinks",
      "status": "queued",
      "notes": "Reuses the schema-mapping and parquet-wasm adapter logic."
    },
    {
      "id": "PRD-LC-012",
      "title": "Cloud Runtime & Execution Bridge",
      "status": "in-progress",
      "notes": "Requires the cloud worker environment to be functional."
    }
  ],
  "technicalNotes": {
    "authModel": "Azure Key Vault + Managed Identity for secret retrieval; OAuth 2.0 Client Credentials for platform handshakes.",
    "streamingStrategy": "SAB binary segments -> parquet-wasm -> HTTP Multipart stream to Snowflake Stage / Databricks Volume.",
    "schemaReuse": "Maps 'bus://' schema fields directly to Snowflake/Databricks DDL (e.g., float64 -> DOUBLE).",
    "errorHandling": "Exponential backoff for 5xx errors; partial success logging; JobID-linked delivery receipts."
  },
  "userStories": [
    {
      "id": "US-CONN-01",
      "title": "Snowflake Direct-to-Stage Sink",
      "story": "As a data engineer, I want to stream results directly into Snowflake without intermediate blob storage hop.",
      "acceptanceCriteria": [
        "Config support: platform: 'snowflake', stage: 'internal_stage_name'.",
        "Orchestrator reuses schema from PRD-LC-018 to verify column compatibility.",
        "Automatic generation of 'COPY INTO' command upon stream completion.",
        "Managed Identity: Cloud worker retrieves Snowflake secrets from Azure Key Vault automatically."
      ],
      "tech_stack": ["Snowflake SQL API", "Azure Key Vault"],
      "passes": false
    },
    {
      "id": "US-CONN-02",
      "title": "Databricks Unity Catalog Integration",
      "story": "As a researcher, I want results to land in a Databricks Volume for instant notebook analysis.",
      "acceptanceCriteria": [
        "Config support: platform: 'databricks', volume: 'unity_volume_path'.",
        "Direct PUT to Databricks REST API using Unity Catalog tokens.",
        "Success metric: 100M records (5GB total) uploaded and queryable in < 90s (intra-region).",
        "Auto-Discovery: New Parquet artifacts appear in Databricks Catalog immediately."
      ],
      "tech_stack": ["Databricks SDK", "parquet-wasm"],
      "passes": false
    },
    {
      "id": "US-CONN-03",
      "title": "Cost & Budget Guardrails",
      "story": "As a CFO, I want a cost estimate before I trigger a multi-terabyte stream to an external partner.",
      "acceptanceCriteria": [
        "UI displays: 'Estimated Transfer: ~X GB, Estimated Egress Cost: $Y'.",
        "System enforces configurable 'Hard Budget' limits per SinkID.",
        "Egress telemetry is logged to cloud monitoring with tenant/project tags."
      ],
      "tech_stack": ["Azure Monitor", "React"],
      "passes": false
    }
  ],
  "filesToCreate": [
    "livecalc-cloud/api/sinks/snowflake_adapter.py",
    "livecalc-cloud/api/sinks/databricks_adapter.py",
    "livecalc-cloud/api/services/secret_manager.py"
  ],
  "estimatedSessions": "4 FADE sessions",
  "definitionOfDone": [
    "Verified minimal-hop streaming (no disk write) to Snowflake and Databricks endpoints.",
    "Credentials retrieved securely via Managed Identity (0 hardcoded secrets).",
    "Schema validation prevents 'Bad Data' from entering the analytic platform.",
    "Egress costs are estimated and logged for every run."
  ]
}
```

### PRD-LC-019B-recompute-relay-system.json

```json
{
  "id": "PRD-LC-019B",
  "complexity": "medium",
  "title": "Re-compute Relay System (Just-in-Time Data Spawning)",
  "type": "feature",
  "priority": "medium",
  "status": "proposed",
  "created": "2026-01-25",
  "project": "LiveCalc",
  "phase": 5,
  "description": "Codifies the 'Compute-as-Bandwidth' paradigm. Enables the Universal API to reconstruct historical runs from the Secure Manifest and stream them directly to a destination sink, bypassing the need for expensive cold-storage rehydration.",
  "dependencies": [
    {
      "id": "PRD-LC-019A",
      "title": "Analytic Platform Connectors",
      "status": "proposed",
      "notes": "Uses the platform-specific streaming adapters."
    },
    {
      "id": "PRD-LC-013",
      "title": "Cloud Platform Management",
      "status": "proposed",
      "notes": "Requires the Manifest Service to retrieve historical model/assumption hashes."
    }
  ],
  "technicalNotes": {
    "relayFlow": "User requests JobID -> API pulls Manifest -> AKS Worker Re-Hydrates WASM -> Compute -> Direct Stream to Sink.",
    "statisticalParity": {
      "tolerance": "0.01% for Mean NPV, StdDev, and tail percentiles (P95/P99).",
      "rationale": "Floating-point determinism cannot be guaranteed across compiler/runtime versions over multi-year spans."
    },
    "versionCompatibility": "Supports a compatibility matrix where current engines can replay older manifests using logic shims or legacy Docker images.",
    "cachingStrategy": "Uses node-local emptyDir volumes for LRU caching of hashed model bundles to reduce re-hydration latency."
  },
  "userStories": [
    {
      "id": "US-RELAY-01",
      "title": "Headless Manifest-to-Stream Command",
      "story": "As an auditor, I want to re-generate a historical run securely and send it to a new platform without manual intervention.",
      "acceptanceCriteria": [
        "API endpoint: POST /v1/relay/{jobId}?targetSink={sinkId}.",
        "Authorization: Requesting user must have 'read' permissions on the original Job's tenant scope.",
        "Tenant Isolation: Relay requests are strictly scoped to the user's tenant context.",
        "Lifecycle: Transient namespace is auto-deleted after completion or a 1-hour hard timeout.",
        "Audit Log: Record relay event linking original JobID, requesting User, and destination Sink."
      ],
      "tech_stack": ["FastAPI", "JWT Scopes", "K8s Client"],
      "passes": false
    },
    {
      "id": "US-RELAY-02",
      "title": "Statistical Parity Verification",
      "story": "As a regulator, I want proof that re-computed results are actuarially equivalent to the original signed-off values.",
      "acceptanceCriteria": [
        "Relay worker calculates summary stats (Mean, StdDev, P99) in real-time.",
        "Verification Sequence: (1) Attempt exact hash match, (2) Fallback to statistical comparison if runtime/compiler differs.",
        "Success: Result is within 0.01% tolerance of the original 'Seal of Authenticity' metadata.",
        "Failure: Fail-fast if statistical divergence indicates a model logic regression."
      ],
      "tech_stack": ["NumPy Statistics", "Manifest Service"],
      "passes": false
    },
    {
      "id": "US-RELAY-03",
      "title": "Dependency & Version Validation",
      "story": "As a system, I want to ensure all historical components are available before starting a relay compute.",
      "acceptanceCriteria": [
        "Pre-flight: Verify all manifest dependencies (assumption versions, ESG seeds) are retrievable.",
        "Engine Check: Validate that the manifest version is supported by the current runtime compatibility matrix.",
        "Failure Handling: Return clear error if assumptions were deleted: 'Cannot relay: mortality_v2.1.0 unavailable'."
      ],
      "tech_stack": ["FastAPI", "Assumptions Manager API"],
      "passes": false
    },
    {
      "id": "US-RELAY-04",
      "title": "Historical Model Bundle Caching",
      "story": "As a platform lead, I want relay jobs to start instantly by caching historical bundles on the node.",
      "acceptanceCriteria": [
        "AKS worker checks node-local emptyDir cache using manifest hash as the key.",
        "LRU Eviction: Automatically purge oldest bundles when cache size exceeds 10GB.",
        "Performance: Cache hit achieves < 10s relay cold start vs < 60s for cache miss."
      ],
      "tech_stack": ["K8s emptyDir", "LRU Cache"],
      "passes": false
    }
  ],
  "filesToCreate": [
    "livecalc-cloud/api/services/relay_orchestrator.py",
    "livecalc-cloud/api/services/parity_validator.py",
    "tests/integration/test_historical_reproducibility.py"
  ],
  "filesToModify": [
    {
      "file": "livecalc-cloud/api/main.py",
      "changes": "Mount /v1/relay/ endpoints and background task manager."
    },
    {
      "file": "livecalc-cloud/api/services/manifest_service.py",
      "changes": "Add historical retrieval and version compatibility logic."
    }
  ],
  "estimatedSessions": "4 FADE sessions",
  "definitionOfDone": [
    "A 100K policy x 10 scenario historical run is relayed and streamed in < 120s.",
    "Verification: Relay result passes the 0.01% statistical parity check against original metadata.",
    "Security: Non-authorized relay requests are rejected with 403 Forbidden.",
    "Cost analysis: Compute cycles for relay are documented as < 50% of cold storage rehydration cost."
  ]
}
```

### PRD-LC-019C-parallel-multi-sink-streaming.json

```json
{
  "id": "PRD-LC-019C",
  "complexity": "medium",
  "title": "Parallel Multi-Sink Streaming",
  "type": "feature",
  "priority": "low",
  "status": "proposed",
  "created": "2026-01-25",
  "project": "LiveCalc",
  "phase": 5,
  "description": "Extends the Sink Manager to support simultaneous, non-blocking streaming to multiple endpoints from a single SharedArrayBuffer pointer. Optimized for high-bandwidth cloud egress within the AKS worker runtime.",
  "dependencies": [
    {
      "id": "PRD-LC-018",
      "title": "Local Artifact Sinks",
      "status": "proposed",
      "notes": "Provides the base sink interface and schema validation logic."
    },
    {
      "id": "PRD-LC-019A",
      "title": "Analytic Platform Connectors",
      "status": "proposed",
      "notes": "Utilizes the specific authentication and transport adapters for Snowflake/Databricks."
    }
  ],
  "standardsReferences": [
    "standards/coding.md",
    "standards/api-security.md",
    "standards/infrastructure.md"
  ],
  "technicalNotes": {
    "executionLocation": "Cloud Worker (Server-side) to minimize client-side egress and leverage high-speed data center backplanes.",
    "concurrencyModel": "Uses Python AsyncIO (Cloud) or Node.js Worker Threads (Local) to manage N simultaneous network streams.",
    "referenceCountingImpl": "Atomic counter stored in the SAB header (Offset +24). Each parallel sink increments on start; manager zeros memory only when counter reaches 0.",
    "backpressure": "Slowest-Sink Governor: Ensures memory remains resident until the slowest endpoint completes or hit a 300s timeout.",
    "timeoutPolicy": "Configurable max retention (default: 300s). Slow sinks receive a cancellation error after the deadline to prevent memory exhaustion.",
    "alignmentCompliance": "Strict adherence to PRD-LC-014: All fan-out buffers must maintain 16-byte alignment to support SIMD-enabled Parquet writers."
  },
  "userStories": [
    {
      "id": "US-PAR-01",
      "title": "Simultaneous Multi-Cloud Egress",
      "story": "As a CFO, I want my results to land in my AWS S3 archive and Snowflake BI tool at the same time.",
      "acceptanceCriteria": [
        "Config allows a list of 'sinks' (e.g., ['s3-archive', 'snowflake-prod']) for a single output node.",
        "Zero-Copy Handoff: Workers share the same SAB pointer with no internal memory replication.",
        "Performance: Total time matches the slowest network link (non-additive).",
        "Resilience: A timeout or 5xx error in Sink B does not interrupt the successful completion of Sink A."
      ],
      "tech_stack": ["AsyncIO", "SAB Pointers", "Python/TypeScript"],
      "passes": false
    },
    {
      "id": "US-PAR-02",
      "title": "Parallel Sink Observability & Telemetry",
      "story": "As a platform engineer, I want to track the performance of individual sinks in a parallel run.",
      "acceptanceCriteria": [
        "Per-sink delivery receipts logged with SinkID, JobID, and total bytes transferred.",
        "Reference counter state transitions (Inc/Dec) are logged for memory leak auditing.",
        "Timeout events are flagged with 'Slow Sink' metadata for infrastructure tuning."
      ],
      "tech_stack": ["Azure Monitor", "OpenTelemetry"],
      "passes": false
    }
  ],
  "filesToCreate": [
    "livecalc-engine/js/src/sinks/parallel-sink-manager.ts",
    "livecalc-cloud/worker/src/sinks/parallel_sink_manager.py",
    "livecalc-cloud/worker/src/sinks/reference_counter.py",
    "tests/performance/test_multi_sink_overhead.ts",
    "tests/integration/test_reference_counting.py"
  ],
  "filesToModify": [
    {
      "file": "livecalc-engine/js/src/orchestrator.ts",
      "changes": "Add logic to detect multiple sinks and initialize the Reference Counter in the SAB header."
    }
  ],
  "estimatedSessions": "4 FADE sessions",
  "definitionOfDone": [
    "Measured overhead of adding a second parallel sink is < 5% CPU/Time in cloud environments.",
    "Memory Leak Test: 1,000 iterations with random simulated sink failures show 0 memory growth.",
    "Timeout Test: A simulated slow sink (10min) is cancelled after 300s without blocking fast sinks.",
    "Standards Verification: Automated test suite verifies 16-byte alignment of all fan-out buffers."
  ]
}
```

### PRD-LC-030-standards-enhancements.json

```json
{
  "id": "PRD-LC-030",
  "complexity": "medium",
  "title": "Standards Documentation Enhancements & Templates",
  "type": "documentation",
  "priority": "low",
  "status": "proposed",
  "created": "2026-01-25",
  "project": "LiveCalc",
  "phase": 1,
  "description": "Enhance existing standards documentation with additional patterns, best practices, and reusable templates. Moves standards from 'gold' to 'platinum' level with comprehensive examples and tooling.",
  "problem": [
    "Standards documentation is comprehensive but could benefit from more code examples",
    "No templates exist for common tasks (ADRs, PRs, security checklists, runbooks)",
    "Some advanced patterns are not yet documented (async/await, SAB best practices, WASM memory management)",
    "Azure-specific infrastructure patterns need documentation",
    "Test data generation strategies not documented"
  ],
  "solution": [
    "Add advanced patterns to existing standards (async/await, SharedArrayBuffer, WASM)",
    "Create standards/templates/ directory with reusable templates",
    "Add more code examples throughout standards files",
    "Document Azure-specific patterns for infrastructure",
    "Add test data generation and snapshot testing guidance"
  ],
  "dependencies": [],
  "technicalNotes": {
    "approach": "Incremental enhancement - each user story adds value independently",
    "templates": "Follow industry standards where they exist (ADR format, GitHub PR templates)",
    "examples": "Real code from LiveCalc codebase, not synthetic examples",
    "priority": "Low priority - existing standards are already comprehensive and functional"
  },
  "userStories": [
    {
      "id": "US-ENH-01",
      "title": "Enhanced Coding Standards Patterns",
      "story": "As a developer, I want advanced patterns documented so I can handle complex scenarios correctly.",
      "acceptanceCriteria": [
        "Add async/await best practices section to standards/coding.md",
        "Document SharedArrayBuffer best practices (allocation, lifecycle, cleanup)",
        "Add WASM-specific conventions (memory management, function exports, Module pattern)",
        "Document Promise.all vs sequential await patterns",
        "Add error handling patterns for async code",
        "Include real code examples from livecalc-engine and livecalc-vscode"
      ],
      "tech_stack": ["Markdown"],
      "passes": false,
      "estimatedEffort": "2 hours"
    },
    {
      "id": "US-ENH-02",
      "title": "Security Enhancement - OAuth Flows & API Versioning",
      "story": "As a platform engineer, I want detailed security patterns documented so I can implement APIs correctly.",
      "acceptanceCriteria": [
        "Add OAuth 2.0 flow diagrams to standards/api-security.md (Authorization Code, Client Credentials)",
        "Document API versioning strategy (URL-based: /v1/, /v2/ vs header-based)",
        "Create security checklist template in standards/templates/security-checklist.md",
        "Add threat modeling template with STRIDE categories",
        "Document API deprecation communication strategy (warnings, timelines, migration guides)",
        "Include example API security review checklist"
      ],
      "tech_stack": ["Markdown", "Mermaid"],
      "passes": false,
      "estimatedEffort": "3 hours"
    },
    {
      "id": "US-ENH-03",
      "title": "Infrastructure Enhancements - Azure Patterns & DR",
      "story": "As a platform engineer, I want Azure-specific patterns documented so I can deploy infrastructure confidently.",
      "acceptanceCriteria": [
        "Add Azure-specific patterns to standards/infrastructure.md:",
        "  - AKS cluster configuration (node pools, autoscaling, networking)",
        "  - Azure Blob Storage lifecycle policies",
        "  - Azure Batch pool configuration",
        "  - Azure Key Vault secret rotation",
        "Document cost monitoring requirements (budgets, alerts, cost allocation tags)",
        "Create disaster recovery runbook template in standards/templates/dr-runbook.md",
        "Add infrastructure change review checklist",
        "Document blue/green deployment strategy for AKS"
      ],
      "tech_stack": ["Markdown", "Terraform", "Kubernetes"],
      "passes": false,
      "estimatedEffort": "3 hours"
    },
    {
      "id": "US-ENH-04",
      "title": "Testing Enhancements - Snapshots, Data Generation, Fuzzing",
      "story": "As a developer, I want advanced testing strategies documented so I can test complex scenarios effectively.",
      "acceptanceCriteria": [
        "Add snapshot testing guidance to standards/testing.md:",
        "  - When to use snapshots (UI output, serialization formats)",
        "  - How to review snapshot diffs",
        "  - Tools: Jest snapshots for TypeScript, pytest-snapshot for Python",
        "Document test data generation strategies:",
        "  - Faker.js for realistic data",
        "  - Property-based testing with fast-check",
        "  - Seed-based reproducibility for stochastic tests",
        "Add fuzzing requirements for critical paths (policy parsing, WASM input validation)",
        "Document performance testing patterns (warmup, statistical significance)",
        "Include test data management best practices (fixtures, builders, factories)"
      ],
      "tech_stack": ["Markdown", "Jest", "pytest"],
      "passes": false,
      "estimatedEffort": "2 hours"
    },
    {
      "id": "US-ENH-05",
      "title": "Git Enhancements - Rebase, Hotfix, Hooks",
      "story": "As a developer, I want advanced Git workflows documented so I can handle complex scenarios.",
      "acceptanceCriteria": [
        "Add rebase vs merge guidance to standards/git.md:",
        "  - When to rebase (feature branches, cleaning up history)",
        "  - When to merge (preserving context, main/release branches)",
        "  - Interactive rebase for commit cleanup",
        "Document hotfix workflow:",
        "  - Branch from main: hotfix/critical-issue",
        "  - Fast-track review process",
        "  - Merge to main and backport to active branches",
        "Add git hooks examples:",
        "  - pre-commit: linting, formatting, test file co-location check",
        "  - commit-msg: conventional commit validation",
        "  - pre-push: run unit tests",
        "Document conflict resolution strategies",
        "Add git bisect usage for debugging regressions"
      ],
      "tech_stack": ["Markdown", "Bash"],
      "passes": false,
      "estimatedEffort": "2 hours"
    },
    {
      "id": "US-ENH-06",
      "title": "Documentation Templates & ADRs",
      "story": "As a developer, I want reusable templates so I don't have to reinvent documentation structure.",
      "acceptanceCriteria": [
        "Create standards/templates/ directory structure:",
        "  - adr-template.md (Architecture Decision Record)",
        "  - pr-description-template.md (Pull Request template)",
        "  - security-checklist.md (API security review checklist)",
        "  - dr-runbook-template.md (Disaster recovery runbook)",
        "  - incident-postmortem-template.md (Post-incident review)",
        "ADR template includes: Title, Status, Context, Decision, Consequences, Alternatives Considered",
        "PR template includes: Summary, Changes, Testing, Deployment Notes, Rollback Plan",
        "Document ADR numbering scheme (ADR-001, ADR-002, etc.)",
        "Add video/screenshot guidelines to standards/documentation.md:",
        "  - Preferred formats (MP4 for video, PNG for screenshots)",
        "  - Annotations: use red boxes/arrows, avoid text unless necessary",
        "  - Storage: commit small images (<500KB), link to external for large files",
        "Update standards/documentation.md to reference templates directory"
      ],
      "tech_stack": ["Markdown"],
      "passes": false,
      "estimatedEffort": "2 hours"
    }
  ],
  "filesToCreate": [
    "standards/templates/adr-template.md",
    "standards/templates/pr-description-template.md",
    "standards/templates/security-checklist.md",
    "standards/templates/dr-runbook-template.md",
    "standards/templates/incident-postmortem-template.md",
    "standards/templates/README.md"
  ],
  "filesToModify": [
    {
      "file": "standards/coding.md",
      "changes": "Add async/await patterns, SharedArrayBuffer best practices, WASM-specific conventions"
    },
    {
      "file": "standards/api-security.md",
      "changes": "Add OAuth flow diagrams, API versioning strategy, deprecation process"
    },
    {
      "file": "standards/infrastructure.md",
      "changes": "Add Azure-specific patterns (AKS, Blob, Batch, Key Vault), cost monitoring, DR strategy"
    },
    {
      "file": "standards/testing.md",
      "changes": "Add snapshot testing, test data generation, fuzzing, performance testing patterns"
    },
    {
      "file": "standards/git.md",
      "changes": "Add rebase vs merge guidance, hotfix workflow, git hooks examples, bisect usage"
    },
    {
      "file": "standards/documentation.md",
      "changes": "Add video/screenshot guidelines, reference templates directory, ADR numbering"
    }
  ],
  "definitionOfDone": [
    "All 6 user stories complete with enhanced content and examples",
    "standards/templates/ directory created with all 5 templates",
    "Each template includes clear instructions and real examples",
    "All modified standards files updated with new sections",
    "Cross-references between standards files updated where needed",
    "No conflicting guidance introduced",
    "Documentation reviewed for clarity and completeness"
  ],
  "successCriteria": {
    "mustHave": [
      "Templates directory with ADR, PR, security checklist, DR runbook",
      "Async/await and SharedArrayBuffer patterns documented",
      "Azure-specific infrastructure patterns documented",
      "Advanced testing strategies documented"
    ],
    "niceToHave": [
      "Video/screenshot guidelines with examples",
      "Git hooks examples tested and verified",
      "Threat modeling template with real LiveCalc examples"
    ]
  },
  "estimatedSessions": "1 FADE session (or split across multiple sessions)",
  "risks": [
    {
      "risk": "Templates become outdated as project evolves",
      "likelihood": "medium",
      "impact": "low",
      "mitigation": "Include 'last updated' date in each template. Review templates quarterly."
    },
    {
      "risk": "Too many examples make standards overwhelming",
      "likelihood": "low",
      "impact": "low",
      "mitigation": "Keep examples concise. Link to real code in repo for detailed examples."
    },
    {
      "risk": "Azure-specific patterns limit cloud portability",
      "likelihood": "low",
      "impact": "low",
      "mitigation": "Document cloud-agnostic principles alongside Azure specifics. Note where patterns are Azure-specific."
    }
  ],
  "notes": [
    "This PRD is intentionally low priority - existing standards (PRD-LC-014) are comprehensive and functional",
    "User stories can be implemented independently - pick high-value items first",
    "Estimated total effort: 14 hours (can be split across multiple sessions)",
    "Consider implementing US-ENH-06 (templates) first as it provides immediate value"
  ]
}
```

## Completed PRDs (Archive)

- PRD-LC-001-cpp-projection-engine.json
- PRD-LC-002-wasm-compilation-threading.json
- PRD-LC-003-vscode-extension-foundation.json
- PRD-LC-004-results-panel-visualisation.json
- PRD-LC-005-auto-run-hot-reload.json
- PRD-LC-006-assumptions-manager-integration.json
- PRD-LC-010-modular-orchestration-layer.json
- PRD-LC-012-cloud-runtime-execution-bridge.json
- PRD-LC-013-cloud-platform-management.json
- PRD-LC-014-standards-documentation.json
- SPIKE-LC-007-engine-performance-infrastructure.json
- SPIKE-SPIKE-LC-007-calcengine.json

